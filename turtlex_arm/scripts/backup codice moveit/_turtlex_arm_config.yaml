turtlex_arm: # namespace. If this is commented, uncomment the namespace in the main launch file

    #qlearn parameters
    alpha: 0.01 # learning rate
    alpha_decay: 0.01
    gamma: 1.0 # future rewards value: 0 = none, 1 = a lot
    epsilon: 1.0 # exploration: 0 = none, 1 = a lot
    epsilon_decay: 0.995 # how much to reduce the exploration value
    epsilon_min: 0.01 # minimum value that epsilon can have

    batch_size: 64 # maximum size of the batches sampled from memory
    episodes_training: 40
    episodes_testing: 10
    n_win_ticks: 50 # if the mean of the rewards is bigger than this value and min_episodes are elapsed, the task is considered finished
    min_episodes: 10

    monitor: True
    quiet: False

    # Fetch-related parameters
    n_actions: 6 # X+/-,Y+/-,Z+/-
    n_observations: 4 # XYZ of the TCP (Tool Center Point) and the distance from GOAL
    position_ee_max: 1.0
    position_ee_min: -1.0
    position_delta: 0.1 # increments or decrements in the X/Y/Z positions each action step

    step_punishment: -1
    closer_reward: 10
    impossible_movement_punishment: -100
    reached_goal_reward: 100

    joints_min_pos: [-2.617, -1.571, -1.571, -1.745, -2.617]
    joints_max_pos: [ 2.617,  1.571,  1.571,  1.745,  2.617]

    init_pos: # rest_arm position
      joint_1: 0.0
      joint_2: -1.0
      joint_3: 1.0
      joint_4: 1.2
      joint_5: 0.0

    setup_ee_pos: # this has to be validated in the fetch_moveit_test.py in fetch_openai_ros_example or something that tests this configuration is possible
      x: 0.598
      y: 0.005
      z: 0.9

    goal_ee_pos: # this has to be validated in the fetch_moveit_test.py in fetch_openai_ros_example or something that tests this configuration is possible
      x: 0.3
      y: 0.0
      z: 0.15

    max_distance: 1.0 # maximum distance of the EE to the desired GOAL EE

    world_name: 'office'
