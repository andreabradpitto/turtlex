turtlex_nav: # namespace

    #SAC parameters
    gamma: 0.99
    tau: 0.01
    alpha: 0.2
    learning_rate: 0.0003
    actor_hidden_dim: 30
    critic_hidden_dim: 500
    batch_size: 64  # maximum size of the batches sampled from memory
    replay_buffer_size: 50000

    training: True  # True for training, False for testing
    testing_goals: 100  # amount of random testing goals to attempt
    test_areas: 8  # number between 1 and 8, for the office world

    load_model: False  # set the NUMBER or 'NAME' of the network to load, set False to skip loading (i.e. train from scratch)

    nepisodes: 10000
    nsteps: 600

    running_step: 0.2  # TODO era 0.06, ma mi sa che non veniva usato... # Time for each step (amount of time in which the control will be executed)

    monitor: True  # Dedice whether to start the Gym Monitor wrapper or not

    # define how many decimal digits to allow in the observation vector
    rounding_value: 2

    max_idle_steps: 20  # Set maximum idle steps allowed

    world_name: 'office'

    # current world bounds
    world_bounds:
       x_max:   5.0
       x_min:  -5.0
       y_max:   2.0
       y_min: -13.0

    desired_pose:
       x: [  1.0,  3.0, -3.0, -3.8,  1.5,  1.0,  3.0, -3.0, -3.5, -3.0,  0.0,  3.2,  3.0]
       y: [ -1.0,  0.0, -1.0,  0.0, -3.5, -7.0, -5.0, -5.0, -7.0,-11.5,-10.0, -8.0,-11.5]

    init_linear_forward_speed: 0.0  # Initial linear speed in which we start each episode
    init_linear_turn_speed: 0.0  # Initial angular speed in which we start each episode
    
    action_v_min: 0.0  # m/s
    action_v_max: 0.22  # m/s
    action_w_min: -2.  # rad/s
    action_w_max: 2.  # rad/s
    
    min_range: 0.25  # Minimum meters below wich we consider we have crashed; 2x max robot reach = ~0.33 x 2 ~= 0.6 ? # TODO i mobili pi√π profondi sono 0.6, gli altri 0.5

    n_sectors: 10  # number of sectors for the state. As the laser sensor is composed by 720 rays: only input values that are its divisor
    n_actions: 2  # linear and angular velocities

    end_episode_points: 300  # Points given when ending an episode. May be positive or negative, depending on episode result
    decrease_goal_distance: -0.5
    increase_goal_distance: -1
